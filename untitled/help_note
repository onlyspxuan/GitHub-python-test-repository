1、
#-*- coding:utf-8 -*-
#coding=utf-8

2、
if __name__ == "__main__":

3、
import requests   #
import urllib.error,urllib.request  #制定URL，获取网页数据
import os
from bs4 import BeautifulSoup  #网页解析，获取数据
imfrom re   #正则表达式，进行文字匹配
import xlwt   #进行execl操作
import sqlite3  #进行sqlite数据库操作

4、
#1、爬取网页
datalist = getData()
#2、逐一解析数据
#3、保存数据

5、#对获取到的网页源码进行utf-8解码
# print (response)
# print (response.read())
print (response.read().decode(utf-8))
#用url链接获取返回的内容，建议最好用decode(utf-8)的形式进行解码


6、
httpbin.org  #一个专门用来测试http/https的网址


7、
Ctrl +/       #将所选语句进行快速注释

8、#异常处理
try:
    response = urllib.request.urlopen("http://httpbin.org/get",timeout=0.001)
    print(response.read().decode('utf-8'))
except urllib.error.URLError as err: #  as err可加可不加
    print('time out ')


9、
"" 与 ''  在使用上基本没什么区别，一般可以互用

10、爬虫
urllib.error.HTTPError: HTTP Error 418:
#返回值为418则被爬虫网站已发现被爬虫


11、 针对反爬虫
#针对反爬虫1_httpbin.org
url = "http://httpbin.org/post" \

#url = 'https://www.douban.com'
headers = {
"User-Agent": "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.74 Safari/537.36"
}
data = bytes(urllib.parse.urlencode({'name':'xuan'}),encoding='utf-8')
req = urllib.request.Request(url=url,data=data,headers=headers,method="POST")
response = urllib.request.urlopen(req)
print(response.read().decode("utf-8"))



# 针对反爬虫2_douban
url = 'https://www.douban.com'
headers = {
"User-Agent": "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.74 Safari/537.36"
}
req = urllib.request.Request(url=url,headers=headers) #data参数可以为空
response = urllib.request.urlopen(req)
print(response.read().decode("utf-8"))


12、 bs4
from bs4 import  BeautifulSoup


file = open("./baidu.html","rb")  #rb  打开一个文档，二进制的读取
html = file.read()    #读取一个文档，作为一个对象
bs = BeautifulSoup(html,"html.parser")  #使用一个名字叫html.parser 的解析器来解析这个html文档



13、正则表达式  re

#【正则常用操作符】  （以下都只表示一位）
.       表示任何单个字符
[ ]     字符集，表示对面单个字符给出的取值范围     [abc]、[a-z]
[^ ]    非字符集，对单个字符给的排除范围
*       前一个字符0次或无限次扩展     abc*——>ab、abc、abcc、abccc等
+       前一个字符1次或无限次扩展     abc+——>abc、abcc、abccc等 （c至少一次）
?       前一个字符0次或1次扩展        abc?——>ab或abc
|       左右表达式任一个             abc|def ——>abc或def（要么左边、要么右边）

{m}     前一个字符出现m次              ab{2}c——>abbc
{m,n}   前一个字符出现m至n次            ab{1,2}c——>abc,abbc
^       以匹配字符串开头                ^abc  ——>以abc开头的字符串
$       以匹配字符串结尾                $abc  ——>以abc结尾的字符串
()     分组标记，括号内部被看做一个整体，内部只能用|操作符     (abc) ——>abc
\d       数字，等价于[0-9]   (只表示一位)
\w       单词字符，，等价于[A-Za-z0-9_]   （不表示汉字）


#【re库主要函数】
re.compile()   创建正则表达式对象，表示规则（字符串的模式）
re.search()    匹配字符串第一个
re.match()
re.findall()            ☆
re.split()
re.finditer()
re.sub()                ☆


#【模式限定】
re.l   使匹配对大小写不敏感
re.L
re.M
re.S
re.U
re.X




14、
pip install --upgrade pip    #pip升级
easy_install  pip      #若无pip，则进行安pip

